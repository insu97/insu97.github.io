---
layout : markdown
title : 상수도 관망 이상 감지 AI 알고리즘 개발
tags : [Dacon, Time-Series, Anomaly_Detection]
toc : true
---

{% include markdown.html %}

> [Dacon_site](https://dacon.io/) | [Github_site]()

---

# Meta Data

```python
# TRAIN_A.csv [파일]: A 관망 구조의 분 단위 데이터 (24/05/27 00:00 ~ 24/06/26 15:00)
# TRAIN_B.csv [파일]: B 관망 구조의 분 단위 데이터 (24/07/01 00:00 ~ 24/07/29 23:59)
# timestamp: 분 단위 시점
# Q: 유량
# M: 펌프가동정보 (On=1, Off=0)
# P: 압력
# anomaly: 해당 시점에서의 정상(0), 이상(1) 여부
# P_flag: 해당 시점에서의 압력계의 정상(0), 이상(1) 여부


# test [폴더]: 예측 현재 시점 T를 포함한 최대 일주일(Lookback 기간)에 대한 평가 데이터 샘플
# C [폴더]: C 관망 구조의 현재 예측 시점 T로 구성된 TEST_C_0000.csv ~ TEST_C_2919.csv의 추론용 평가 데이터 샘플
# D [폴더]: D 관망 구조의 현재 예측 시점 T로 구성된 TEST_D_0000.csv ~ TEST_D_2737.csv의 추론용 평가 데이터 샘플
# timestamp: 현재 시점 T가 비식별화된 분 단위 시점
# Q: 유량
# M: 펌프가동정보 (On=1, Off=0)
# P: 압력


# meta_관망구조이미지 [폴더]
# train [폴더]: A, B 관망 구조 이미지
# test [폴더]: C, D 관망 구조 이미지


# test.csv [파일]
# ID : 평가 데이터 샘플 식별 ID
# path : 평가 데이터 샘플 경로


# sample_submission.csv [제출 양식]
# ID : 평가 데이터
# P : 압력에 대한 정상 or 비정상 구분
```

# Data Info

## Columns

```python
df_A = pd.read_csv("../data/train/TRAIN_A.csv")
df_B = pd.read_csv("../data/train/TRAIN_B.csv")

df_A['timestamp'] = pd.to_datetime(df_A['timestamp'], format='%y/%m/%d %H:%M')
df_B['timestamp'] = pd.to_datetime(df_B['timestamp'], format='%y/%m/%d %H:%M')

df_A.set_index('timestamp', inplace=True)
df_B.set_index('timestamp', inplace=True)

sub_df = pd.read_csv("../data/sample_submission.csv")
sub_df.head()
```
![image_001](/assets/images/dacon/Dacon_003.png)

- flag_list
1. test_c 일 때 -> P1 ~ P8 까지 변수 사용
2. test_d 일 때 -> P1 ~ P6 까지 변수 사용

> 따라서 두 가지 경우로 나눠서 학습

```python
x_c_col = ['P1','P2','P3','P4','P5','P6','P7','P8']
x_d_col = ['P1','P2','P3','P4','P5','P6']

y_col = 'anomaly'
```

# TEST C

```python
df_A_C = df_A[x_c_col + [y_col]]
df_B_C = df_B[x_c_col + [y_col]]

df_C = pd.concat([df_A_C, df_B_C])
```

- 간단한 시각화

```python
import matplotlib.pyplot as plt

# 서브플롯 생성
fig, axes = plt.subplots(2, 4, figsize=(20, 10))  # 2행 4열의 서브플롯
axes = axes.flatten()  # 2D 배열 -> 1D로 평탄화

# 각 피처별 그래프 그리기
for i, feature in enumerate(x_c_col):
    axes[i].scatter(df_C.index, df_C[feature], c=df_C['anomaly'], cmap='coolwarm', s=10, label=feature)
    axes[i].set_title(f'{feature}', fontsize=14)
    axes[i].set_xlabel('Index')
    axes[i].set_ylabel(feature)
    axes[i].legend(loc='upper right')

plt.show()
```

![image_002](/assets/images/dacon/Dacon_004.png)

## preprocessing

### MinMaxScaler

```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(0, 1))

df_C.loc[:, x_c_col] = scaler.fit_transform(df_C.loc[:, x_c_col])
```

### train_test_split

```python
from sklearn.model_selection import train_test_split

# 독립 변수(X)와 종속 변수(y) 분리
X = df_C.drop(columns=['anomaly'])
y = df_C['anomaly']

# 시계열 순서 유지하며 분리
split_idx = int(len(X) * 0.8)
x_train, x_val = X.iloc[:split_idx], X.iloc[split_idx:]
y_train, y_val = y.iloc[:split_idx], y.iloc[split_idx:]
```

## Modeling

```python
from sklearn.ensemble import IsolationForest
from sklearn.metrics import classification_report, accuracy_score

# Isolation Forest 모델 학습
model = IsolationForest(contamination=0.05, random_state=42)  # 이상치 비율 설정
model.fit(x_train)

# x_val에 대한 예측 수행
val_predictions = model.predict(x_val)

# 예측값 변환 (-1 → 1, 1 → 0)
val_predictions = (val_predictions == -1).astype(int)

from sklearn.metrics import classification_report, accuracy_score

# 성능 평가
print("Classification Report:")
print(classification_report(y_val, val_predictions))

# 정확도
accuracy = accuracy_score(y_val, val_predictions)
print(f"Accuracy: {accuracy:.2f}")
```

![image_003](/assets/images/dacon/Dacon_005.png)

---

# 앞으로 추가해야 할 것
1. Test_C, Test_D 데이터에 대해서 학습한 모델로 예측한 값을 submission에 넣은 뒤 제출해보기
2. 시각화를 통해 Train_A, Train_B 데이터의 범위가 차이가 많이 있음을 확인 -> 해결방법 생각해보기
