---
layout : markdown
title : DLFS1
tags : [DLfS1, DeepLearning]
---

{% include markdown.html %}

# 밑바닥부터 시작하는 딥러닝1

1. 딥러닝은 입력층, 은닉층, 출력층 존재
2. 활성화 함수가 존재
  - 은닉층 : Sigmoid, ReLU
  - 출력층
  > 회귀문제 : 항등함수  
  > 이진분류 : sigmoid  
  > 다중분류 : Softmax  
3. 손실함수
  - 회귀문제 : MSE, RMSE
  - 분류문제 : CEE
4. 가중치 초깃값
  - 선형 : Xavier 초깃값 사용
  - ReLU : He 초깃값 사용
5. 매개변수 갱신 방법
  - 수치 미분 사용
  - 경사 하강법
  - 확률적 경사하강법
  - 모멘텀
  - Adagrad
  - Adam
  - Nesterov
  - RMSprop
6. 배치 정규화 기법
  : Affine -> Batch Norm -> ReLU
7. 오버피팅 시  
  - Dropout  
  - 가중치 감소[ 손실 함수에 가중치의 L2노름을 더한 가중치 감소 방법 ]    
  - 적절한 하이퍼파라미터 값 찾기  
    - 데이터 분할
    > 훈련 데이터 : 데이터 학습
    > 검증 데이터 : 하이퍼파라미터 성능 평가  
    > 시험 데이터 : 신경망의 범용 성능 평가  

    - 하이퍼파라미터 최적화 : 그리드 서치보다는 무작위로 샘플링해 탐색하는 편이 좋다고 알려짐


---

- site : [구현_Site](https://deeplearning01.streamlit.app/)
