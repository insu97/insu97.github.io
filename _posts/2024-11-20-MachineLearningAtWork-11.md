---
layout : markdown
title : Machine Learning At Work - 11
tags : [Machine_Learning_At_Work, Book]
toc : true
---
{% include markdown.html %}

# 슬롯머신 알고리즘을 활용한 강화 학습 입문

> 현실에서는 데이터가 충분하지 않거나 데이터 수집에 상당한 비용이 든다.  
> 이때는 지도 학습을 하지 않고 훈련 데이터를 수집하는 동시에 학습을 수행하는 강화 학습을 활용

## 슬롯머신 알고리즘 용어 정리

- 팔 : 어떤 시점에서 선택 가능한 선택지를 의미
- 방책 : 미리 정한 알고리즘에 따라 팔을 선택하는 방법을 의미, 정책(policy)라고도 하며 방책에 따라 슬롯머신 알고리즘의 성능이 좌우한다.
- 시행 : 팔을 선택하면 얻는 보상을 의미한다. '(팔을)당긴다'라는 용어로 사용하기도 한다.
- 보상 : 어떤 팔을 선택했을 때 얻을 수 있는 가치를 의미한다. return이라 부르기도 한다. 각 팔의 고유한 확률 밀도 분포에 따라 보상을 얻는다고 가정
- 표본 : 시행 결과에 따라 얻는 보상의 집합을 의미, 당기는 팔이 같아도 얻는 보상은 매번 다르다는 것에 주의
- 탐색 : 적은 시행 횟수로 정보가 많지 않아 모평균이 불확실한 팔을 선택하는 것을 의미,
> 탐색을 통해 선택한 팔의 시행 횟수가 증가하면 그에 따라 정보의 양도 증가해 신뢰 구간이 좁아진다.
- 활용 : 여러 팔 중에서 모평균이 큰 팔을 선택하는 것을 의미, 활용을 통해 여러 차례 시행해 누적 보상을 최대화하는 것을 목표로 한다.

## 확률적 슬롯머신 알고리즘

```
비즈니스 현장에서는 최적의 팔을 선택하는 것이 반드시 최적의 전략이라고는 할 수 없다.
비슷한 수준의 보상을 제공하는 팔이 여럿이라면 어떤 것을 선택해도 무방하다.
```

## 알고리즘 종류

1. 무작위 알고리즘
2. 베이즈 UCB, UCB1
3. 소프트맥스 알고리즘
4. 어닐링 소프트맥스
5. TS 알고리즘

## 정리

```
기존의 라이브러리
- ZOZO Technologies에서 공개한 OPEN BANDIT PIPELINE
- 각종 콘텍스트 기반 슬롯머신 알고리즘을 비교한 contextualbandits

슬롯머신 알고리즘은 훈련 데이터가 없거나 사용자에게 추천할 때 효과적으로 동작
```

## 후기

> 책을 보면서 수식은 이해가 가지만 작동원리나 실제 사례에서 사용한 코드에 대한 이해가 부족  
> 조금 자세하게 들여다 보거나 다른 예제를 보면서 이해하는 시간이 필요해 보임
