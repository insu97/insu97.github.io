---
layout : markdown
title : 2024 생명연구자원 AI활용 경진대회 인공지능 활용 부문
tags : [multiclass-classification, dacon]
toc : true
---

{% include markdown.html %}

site : [Dacon_site](https://dacon.io/competitions/official/236355/overview/description)

---

# 생각

- 공모전 신청 후 데이터를 다운받아 **train.shape** 을 찍어보니까 컬럼 수가 약 4천 개가 넘어가는 것을 확인
- **WT** 라는 값이 매우 많고 아주 적게 다른 값이 존재함을 확인
- 평소처럼 원-핫 인코딩을 하면 컬럼 수가 더 증가하는 것을 생각하여 사용 X
- **WT** 값은 중요하지 않다고 보고 **WT** 값은 0 나머지 값은 1로 변경

```python
train[test.columns] = train[test.columns].map(lambda x:0 if x == 'WT' else 1)
test[test.columns] = test[test.columns].map(lambda x:0 if x == 'WT' else 1)
```

- 데이터가 약 6천개의 행과 약 4천개의 컬럼으로 컬럼 수가 많다고 판단  
-- 1. feature 선택 : VarinaceThreshold, Unvariate Feature Selection  
-- 2. 차원축소 : PCA

# 변수 선택
## VarianceThreshold

> 분산 임계값을 충족하지 않는 모든 피처를 제거하는 방식

```python
from sklearn.feature_selection import VarianceThreshold

VT = VarianceThreshold(threshold=(0.02)) # 임계값 정하기
VT.fit_transform(train[test.columns])

VT.get_feature_names_out()  # 남은 피처 확인

# 학습 데이터 재구성
vt_col = VT.get_feature_names_out().tolist()
vt_col.append("SUBCLASS")

train_vt = train[vt_col]
test_vt = test[VT.get_feature_names_out()]
```

## Univariate Feature Selection(UFS)

> 일변량 통계 검정을 기반으로 최적의 피처를 선택  
> 회귀분석일 때 파라미터 : f_rregression, mutual_info_regression  
> 분류분석일 때 파라미터 : chi2, f_classif, mutual_info_classif  

-> 여기서는 분류문제 이므로 chi2를 선택하여 사용했음  

```python
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2 # 카이제곱값 이용

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
import numpy as np

# 가능한 k 값 (몇 개의 변수를 선택할지)
k_values = range(10, 500, 10)  # 10개씩 증가하면서 최대 500개까지 탐색 (필요에 따라 조정 가능)

# 결과 저장 리스트
mean_scores = []

X = train[test.columns]
y = train['SUBCLASS']

# 각 k 값에 대해 교차 검증을 통한 성능 평가
for k in k_values:
    selector = SelectKBest(chi2, k=k)
    X_new = selector.fit_transform(X, y)

    # 분류 모델 정의 (랜덤 포레스트로 예시)
    clf = RandomForestClassifier()

    # 교차 검증을 통한 성능 평가
    scores = cross_val_score(clf, X_new, y, cv=5)  # 5-fold 교차 검증
    mean_scores.append(np.mean(scores))

# 최적의 k 값 찾기
optimal_k = k_values[np.argmax(mean_scores)]
print(f"최적의 k 값: {optimal_k}")
```

-> 최적의 k값을 찾고 학습시킨 후 제출하였는데 **VarianceThreshold** 보다 정확도가 너무 낮게 나왔다.  
-- 이유 ( 내 생각 )
1. RandomForest 분류 모델이 성능이 좋지 않을 때 [ 서포트 벡터 머신 분류 보다 ]
2. 파라미터인 카이제곱값이 성능이 좋지 않은 경우
3. UFS 피쳐 선택방법이 희소행렬일 때 성능이 좋지 않은 경우

---

! 추가적으로 기술해야 할 것
1. 차원축소를 실행할 때 적절한 차원 수 구하는 방법
2. 분류 모델 선정
3. UFS 변수 선택 성능이 좋지 않은 이유 검증

---
# 참고 사이트
1. [머신러닝, 개념과 실습을 한번에](https://curriculum.cosadama.com/machine-learning/2-5/)
2. [PCA, 주성분의 개수는 어떤 기준으로 설정할까?](https://techblog-history-younghunjo1.tistory.com/134)
