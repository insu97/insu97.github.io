---
layout : markdown
title : Discovering Statistics Using R - 002
tags : [Discovering_Statistics_Using_R, R]
toc : true
---
{% include markdown.html %}

- 통계적 모형

1. 전체 오차 = 편차들의 합 => $$ \sum (x_i - \bar{x}) $$
> 오차의 부호에 영향을 받음 -> 해결책 : 오차를 제곱
2. 오차제곱합(SS, sum of squared errors) = $$ \sum(x_i - \bar{x})^2 $$
> data의 크기가 클수록 SS도 커진다. -> 해결책 : 관측값들의 개수 N으로 나누기
3. 분산(variance) = $$ \frac{SS}{N-1} = \frac{\sum(x_i - \bar{x})^2}{N-1}$$
> 단위가 제곱이라는 문제점이 발생 -> 해결책 : 제곱근을 사용
4. 표준편차(standard deviation, SD) = $$ \sqrt{\frac{SS}{N-1}} = \sqrt{\frac{\sum(x_i - \bar{x})^2}{N-1}}$$
> 표준편차가 평균보다 상대적으로 작다는 것은 자료점들이 평균에 가깝다는 의미  
> 표준편차가 평균보다 상대적으로 크다는 것은 자료점들이 평균에 멀다는 의미

---

- 표준오차(SE, standard error) = $$ \sigma _{\bar{x}} = \frac{s}{\sqrt{N}} $$
> 표준오차 : 표본평균들의 표준편차  
> 주어진 표본이 모집단을 얼마나 잘 대표하는지 나타내는 측도  
> 값이 클 경우 : 표본이 모집단을 잘 대표하지 않을 가능성이 크다.  
> 값이 작을 경우 : 표본이 모집단을 정확하게 반영할 가능성이 크다.

---

- 신뢰구간(confidence interval)
> Ex. 신뢰구간 95% 구간  
> 신뢰구간의 하계 = $$ \bar{X} - (1.96 * SE) $$  
> 신뢰구간의 상계 = $$ \bar{X} + (1.96 * SE) $$

- [표본이 작을 때는 t분포를 사용]
> 신뢰구간의 하계 = $$ \bar{X} - (t_{n-1} * SE) $$  
> 신뢰구간의 상계 = $$ \bar{X} + (t_{n-1} * SE) $$

---

> $$ 검증 통계량 = \frac{모형이 설명하는 변동}{모형이 설명하지 못하는 변동} = \frac{효과}{오차}$$  

- 검정 통계량(test statistics) : 체계적 변동 대 비체계적 변동의 비(ratio) 또는 효과 대 오차의 비  

---

- 제1종 오류 : 모집단에 효과가 진짜로 존재한다고 믿지만 사실은 모집단에 아무런 효과도 없는 것
> 피셔의 기준으로 모집단에 효과가 존재하지 않을 때 이 오류가 생갈 확률은 5% = $$ \alpha-수준 $$  
- 제2종 오류 : 모집단에 실제로 효과가 존재하지만 모집단에 아무 효과도 존재하지 않는다고 믿는 것
> 코언은 제2종 오류의 허용 가능한 최대 확룰로 20%를 제안 = $$ \beta-수준 $$
