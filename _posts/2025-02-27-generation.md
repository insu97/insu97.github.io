---
layout: markdown
title: 생성 모델과 판별 모델
tags: [DL, COMPUTER_VISION]
toc: true
---

{% include markdown.html %}

# 생성 모델과 판별 모델

## 생성 모델 (Generative Models)

생성 모델은 데이터 X와 특성 Y의 결합 분포 p(X, Y) 또는 조건부 분포 p(X\|Y)를 추정합니다. Y가 없는 경우, 데이터의 주변 분포 p(X)를 추정합니다.

**가정:** 데이터는 저차원의 필수적인 정보로부터 생성 가능하다고 가정합니다.

**예시:** 가우시안 혼합 모델 (Gaussian Mixture Model, GMM)

### 특징

1. **어려움:**
   - 고차원 데이터 모델링: 복잡한 모든 특성의 분포를 알아야 함
   - 평가 지표: 생성된 데이터에 대한 정량적 평가가 어려움

2. **활용:**
   - 이미지 품질 개선
   - 맥락에 맞는 이미지 자동 완성

### 최대 가능도 추정법 (Maximum Likelihood Estimation, MLE)

가능도를 최대화하는 파라미터 값을 찾는 방법입니다. 일반적으로 가능도 함수의 미분을 통해 계산합니다.

> **Kullback-Leibler Divergence:** 쿨백-라이블러 발산 최소화 = 로그가능도 최대화

### 평가 지표

1. Inception Score(IS)
  - 예리함과 다양성 두 가지를 주요하게 고려
  - IS = Sharpness(S) * Diversity(D)
  - 한계점
     1. 분류기 모델의 훈련 데이터 셋과 다른 데이터를 생성하는 경우 제대로 평가하기 어려움
     2. IS가 높은 데이터를 생성하면 계속 같은 데이터를 생성(Mode Collapse)
     3. 기울기 기반(Gradient Based) 공격, 리플레이(Replay) 공격을 통해 점수 조작 가능
2. Frechet Inception Distance(FID)
   - 생성된 데이터의 특징 벡터를 이용하여 훈련 데이터와의 거리를 계산
   - 훈련 데이터와 생성 데이터를 모두 활용
   - 훈련 데이터와 생성 데이터의 각 분포를 정규 분포로 가정하고, 두 분포의 거리를 Frechet 거리로 계산
   - 한계점
     1. FID 점수는 Fidelity와 Diversity를 각각 평가할 수 없음
3. 개선된 정밀도, 재현율(Improved Precision & Recall)
   - Precision : 생성된 데이터 중에서, 실제 데이터 분포에 아주 가까운 데이터 = (TP) / (TP + FP)
   - Recall : 실제 데이터 중에서, 생성된 데이터 분포에 아주 가까운 데이터 = (TP) / (TP + FN)
   - 한계점
     1. 이상치에 민감
     2. 실제 데이터와 생성된 데이터의 분포가 동일하더라도 샘플링에 따라 점수가 낮을 수 있음
   - 문제 완화
     1. Density : 반경의 합집합이 아닌 가중 합집합으로 계산하여 이상치에 대해 상대적으로 덜 민감
     2. Coverage : 생성된 데이터에 대해 매번 계산하지 않고 실제 데이터 집합으로 미리 계산하여 안정적이고 계산량 감소
4. 조건부 정확도(Conditional Accuracy)
5. Learned Perceptual Image Patch Similarity(LPIPS)
   - 모델 특징 비교를 통한 영상간 유사도 측정
6. CLIP-Score
   - Text와 Image 간의 유사도 측정

## 판별 모델 (Discriminative Model)

```
판별 모델은 데이터 X가 주어졌을 때, 특성 Y가 나타날 조건부 확률 p(Y\|X)를 직접적으로 반환합니다.  
판별 모델은 정답(Ground Truth, GT)가 존재하므로 모델의 출력을 정답과 비교하기 용이  
분류, 회귀 문제로 나눌 수 있음
```
**특징:** 주어진 데이터를 통해 데이터 사이의 경계를 예측합니다.

**예시:** 로지스틱 회귀 분석

## 생성 모델 vs 판별 모델

| 특성 | 생성 모델 | 판별 모델 |
|------|-----------|-----------|
| 추정 | p(X, Y) 또는 p(X\|Y) | p(Y\|X) |
| 접근 방식 | 데이터 생성 과정 모델링 | 클래스 간 경계 학습 |
| 복잡도 | 상대적으로 높음 | 상대적으로 낮음 |
| 데이터 요구량 | 더 많은 데이터 필요 | 적은 데이터로도 가능 |
| 유연성 | 새로운 클래스 추가 용이 | 새로운 클래스 추가 어려움 |

# 오토 인코더

입력 데이터의 패턴을 학습하여 데이터를 재건하는 모델 -> 비선형 차원 축소 기법으로 활용 가능

- **인코더** : 데이터를 저차원 잠재 표현으로 요약
- **디코더** : 저차원 잠재 표현으로부터 데이터를 재구성(Reconstruction)

## 손실함수

잠재 표현으로부터 복구한 데이터와 입력 데이터의 평균제곱오차(MSE)

## 디노이징(Denoising) 오토 인코더

```
입력 데이터에 랜덤 노이즈를 주입하거나 Dropout 레이어를 적용  
노이즈가 없는 원래 데이터로 재구성
```

- 원리 : 노이즈에 강건한 잠재 표현(미세하게 변형된 데이터도 같은 잠재 벡터로 표현되도록)


## 활용

1. 특징 추출기
   - 잠재 벡터로부터 분류, 클러스터링 문제 해결
2. 이상치 탐지(Anomaly Detection)
   - 이상치는 재구성 했을 때 평균제곱오차가 크게 나올 것!
   - 특정 임계값을 넘으면 이상치로 판단

# 변분 오토 인코더(Variation Autoencoder, VAE)

오토 인코더와 동일한 구조(Encoder + Decoder)를 가지는 생성 모델  
잠재 변수 모델 : 데이터는 저차원의 잠재 변수로부터 생성됨

- 잠재 벡터의 분포 : 표준정규분포
- 장점
   1. q(z\|x)로부터 데이터를 요약하는 유용한 잠재 표현을 찾을 수 있음
- 단점
   1. 가능도가 아닌 가능도의 하한을 최대화
   2. 흐릿한 이미지를 생성

## Evidence of Lower BOund(ELBO)

현재 모델이 우리가 가진 현상을 얼마나 잘 설명하는가 = 가능도(Likelihood)  
직접 계산이 어려우니, 간점적으로 계산하여 최대화함
