---
layout: markdown
title: 생성 모델과 판별 모델
tags: [DL, COMPUTER_VISION]
toc: true
---

{% include markdown.html %}

# 생성 모델과 판별 모델

## 생성 모델 (Generative Models)

생성 모델은 데이터 X와 특성 Y의 결합 분포 p(X, Y) 또는 조건부 분포 p(X\|Y)를 추정합니다. Y가 없는 경우, 데이터의 주변 분포 p(X)를 추정합니다.

**가정:** 데이터는 저차원의 필수적인 정보로부터 생성 가능하다고 가정합니다.

**예시:** 가우시안 혼합 모델 (Gaussian Mixture Model, GMM)

### 특징

1. **어려움:**
   - 고차원 데이터 모델링: 복잡한 모든 특성의 분포를 알아야 함
   - 평가 지표: 생성된 데이터에 대한 정량적 평가가 어려움

2. **활용:**
   - 이미지 품질 개선
   - 맥락에 맞는 이미지 자동 완성

### 최대 가능도 추정법 (Maximum Likelihood Estimation, MLE)

가능도를 최대화하는 파라미터 값을 찾는 방법입니다. 일반적으로 가능도 함수의 미분을 통해 계산합니다.

> **Kullback-Leibler Divergence:** 쿨백-라이블러 발산 최소화 = 로그가능도 최대화

### 평가 지표

1. Inception Score(IS)
  - 예리함과 다양성 두 가지를 주요하게 고려
  - IS = Sharpness(S) * Diversity(D)
  - 한계점
     1. 분류기 모델의 훈련 데이터 셋과 다른 데이터를 생성하는 경우 제대로 평가하기 어려움
     2. IS가 높은 데이터를 생성하면 계속 같은 데이터를 생성(Mode Collapse)
     3. 기울기 기반(Gradient Based) 공격, 리플레이(Replay) 공격을 통해 점수 조작 가능
2. Frechet Inception Distance(FID)
   - 생성된 데이터의 특징 벡터를 이용하여 훈련 데이터와의 거리를 계산
   - 훈련 데이터와 생성 데이터를 모두 활용
   - 훈련 데이터와 생성 데이터의 각 분포를 정규 분포로 가정하고, 두 분포의 거리를 Frechet 거리로 계산
   - 한계점
     1. FID 점수는 Fidelity와 Diversity를 각각 평가할 수 없음
3. 개선된 정밀도, 재현율(Improved Precision & Recall)
   - Precision : 생성된 데이터 중에서, 실제 데이터 분포에 아주 가까운 데이터 = (TP) / (TP + FP)
   - Recall : 실제 데이터 중에서, 생성된 데이터 분포에 아주 가까운 데이터 = (TP) / (TP + FN)
   - 한계점
     1. 이상치에 민감
     2. 실제 데이터와 생성된 데이터의 분포가 동일하더라도 샘플링에 따라 점수가 낮을 수 있음
   - 문제 완화
     1. Density : 반경의 합집합이 아닌 가중 합집합으로 계산하여 이상치에 대해 상대적으로 덜 민감
     2. Coverage : 생성된 데이터에 대해 매번 계산하지 않고 실제 데이터 집합으로 미리 계산하여 안정적이고 계산량 감소
4. 조건부 정확도(Conditional Accuracy)
5. Learned Perceptual Image Patch Similarity(LPIPS)
   - 모델 특징 비교를 통한 영상간 유사도 측정
6. CLIP-Score
   - Text와 Image 간의 유사도 측정

## 판별 모델 (Discriminative Model)

```
판별 모델은 데이터 X가 주어졌을 때, 특성 Y가 나타날 조건부 확률 p(Y\|X)를 직접적으로 반환합니다.  
판별 모델은 정답(Ground Truth, GT)가 존재하므로 모델의 출력을 정답과 비교하기 용이  
분류, 회귀 문제로 나눌 수 있음
```
**특징:** 주어진 데이터를 통해 데이터 사이의 경계를 예측합니다.

**예시:** 로지스틱 회귀 분석

## 생성 모델 vs 판별 모델

| 특성 | 생성 모델 | 판별 모델 |
|------|-----------|-----------|
| 추정 | p(X, Y) 또는 p(X\|Y) | p(Y\|X) |
| 접근 방식 | 데이터 생성 과정 모델링 | 클래스 간 경계 학습 |
| 복잡도 | 상대적으로 높음 | 상대적으로 낮음 |
| 데이터 요구량 | 더 많은 데이터 필요 | 적은 데이터로도 가능 |
| 유연성 | 새로운 클래스 추가 용이 | 새로운 클래스 추가 어려움 |

# 오토 인코더

입력 데이터의 패턴을 학습하여 데이터를 재건하는 모델 -> 비선형 차원 축소 기법으로 활용 가능

- **인코더** : 데이터를 저차원 잠재 표현으로 요약
- **디코더** : 저차원 잠재 표현으로부터 데이터를 재구성(Reconstruction)

## 손실함수

잠재 표현으로부터 복구한 데이터와 입력 데이터의 평균제곱오차(MSE)

## 디노이징(Denoising) 오토 인코더

```
입력 데이터에 랜덤 노이즈를 주입하거나 Dropout 레이어를 적용  
노이즈가 없는 원래 데이터로 재구성
```

- 원리 : 노이즈에 강건한 잠재 표현(미세하게 변형된 데이터도 같은 잠재 벡터로 표현되도록)


## 활용

1. 특징 추출기
   - 잠재 벡터로부터 분류, 클러스터링 문제 해결
2. 이상치 탐지(Anomaly Detection)
   - 이상치는 재구성 했을 때 평균제곱오차가 크게 나올 것!
   - 특정 임계값을 넘으면 이상치로 판단

# 변분 오토 인코더(Variation Autoencoder, VAE)

오토 인코더와 동일한 구조(Encoder + Decoder)를 가지는 생성 모델  
잠재 변수 모델 : 데이터는 저차원의 잠재 변수로부터 생성됨

- 잠재 벡터의 분포 : 표준정규분포
- 장점
   1. q(z\|x)로부터 데이터를 요약하는 유용한 잠재 표현을 찾을 수 있음
- 단점
   1. 가능도가 아닌 가능도의 하한을 최대화
   2. 흐릿한 이미지를 생성

## Evidence of Lower BOund(ELBO)

현재 모델이 우리가 가진 현상을 얼마나 잘 설명하는가 = 가능도(Likelihood)  
직접 계산이 어려우니, 간점적으로 계산하여 최대화함

# VQVAE(Vector Quantized Variational Autoencoder)

유한한 잠재 표현을 활용하는 변분 오토 인코더

- 이산(Discrete) 잠재 변수
   - 범주 : K개의 D차원 임베딩(Embedding) 벡터

# 적대적 생성 신경망 (Generative Adverarial Networks, GANs)

적대적으로 학습하는 신경망들로 구성되며, 생성 모댈로써 활용함

- 생성된 데이터와 실제 데이터를 판별하고 속이는 과정을 거치며 생성 모델을 개선
- 데이터를 생성하는 생성 모델과 데이터의 진위를 구별하는 판별 모델(Discriminator)로 구성
   > 판별 모델 : 생성된 데이터를 입력으로 받아 실제 데이터인지 생성된 데이터인지를 출력
- 훈련 과정
   1. 임의의 초기 분포로부터 생성 모델이 데이터를 생성
   2. 판별 모델이 분류; 판별 모델 갱신
   3. 갱신된 판별 모델을 고정;생성 모델 갱신
   4. 반복 과정을 거쳐 생성 모델은 판별 모델이 구별할 수 없는 수준의 데이터를 생성
- 목적 함수
   1. 생성 모델 : 실제와 유사한 데이터를 생성하여 판별자를 속여야 함(다음 목적 함수를 최소화함)
   2. 판별 모델 : 실제와 생성된 데이터를 정확하게 구별해야 함(다음 목적 함수를 최대화함)

# 조건부 생성 모델

- 필요성 : 다양한 활용을 위해 생성 데이터의 의미 제어 방법이 필요함

```
- 조건을 입력 받아 원하는 의미를 갖는 데이터를 생성하는 생성 모델
- 범주(카테고리)부터 영상의 전체 구조(레이아웃)에 이르기까지 다양한 입력을 조건으로 받음
- 높은 다양성과 품질을 동시에 누릴 수 있으나 수집하기 더 까다로운 데이터를 필요로함
```

### 이미지 대 이미지 (Image-to-Image Translation)

1. **Pix2pix**  
   - 조건부 GAN (cGAN)을 기반으로 한 모델  
   - 입력 이미지를 다른 스타일이나 도메인으로 변환  
   - 지도 학습 방식으로 특정 입력-출력 쌍을 필요로 함  
   - 예: 스케치를 컬러 이미지로 변환  

2. **CycleGAN**  
   - 지도 학습 없이 이미지 스타일 변환을 수행  
   - 두 개의 생성자와 판별자를 사용하여 도메인 간 변환을 학습  
   - 예: 말 ↔ 얼룩말, 여름 ↔ 겨울  

3. **BiCycleGAN**  
   - Pix2pix 모델의 확장  
   - 하나의 입력에 대해 다양한 출력을 생성할 수 있도록 개선  
   - 잠재 공간에서 샘플링을 통해 다중 모드 출력 가능  

4. **StarGAN**  
   - 하나의 모델로 여러 개의 도메인 변환을 가능하게 함  
   - 도메인 간 이미지 변환을 하나의 네트워크에서 수행  
   - 예: 얼굴 사진에서 성별, 나이, 감정 변화 적용  

5. **InstaGAN**  
   - 개별 객체 단위의 변환이 가능한 모델  
   - 배경과 객체를 분리하여 변환 적용  
   - 예: 개별적인 얼굴 스타일 변경  

6. **LostGAN**  
   - 객체 수준의 이미지 변환 및 생성에 특화  
   - 레이아웃 정보를 사용하여 장면을 구성  
   - 예: 주어진 레이아웃에 따른 장면 이미지 생성  

7. **SPADE (Spatially-Adaptive Denormalization)**  
   - 레이아웃 정보를 반영한 고품질 이미지 생성  
   - 세그먼트 맵을 활용하여 이미지 스타일 변환  
   - 예: 스케치를 사실적인 장면으로 변환  

---

### 텍스트 대 이미지 (Text-to-Image Generation)

1. **GAN-CLS (GAN with Conditional Latent Space)**  
   - 텍스트 설명을 조건으로 하는 이미지 생성 모델  
   - 텍스트 임베딩을 GAN에 입력하여 관련된 이미지 생성  
   - 예: "붉은 꽃이 핀 초록색 들판" → 해당 이미지 생성  

2. **GigaGAN**  
   - 초고해상도(High-Resolution) 텍스트 기반 이미지 생성 모델  
   - 기존 GAN 기반 텍스트-이미지 모델보다 더 높은 품질과 해상도 제공  
   - 예: 텍스트 입력만으로 사실적인 고해상도 이미지 생성  
