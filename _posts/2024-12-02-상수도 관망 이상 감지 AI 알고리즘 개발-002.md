---
layout : markdown
title : 상수도 관망 이상 감지 AI 알고리즘 개발 - 02
tags : [Dacon, Time-Series, Anomaly_Detection]
toc : true
---

{% include markdown.html %}
> [Dacon_site](https://dacon.io/) | [Github_site](https://github.com/insu97/DACON/tree/main/004.%202024%20%EC%A0%9C4%ED%9A%8C%20K-water%20AI%20%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C%20%20%EC%83%81%EC%88%98%EB%8F%84%20%EA%B4%80%EB%A7%9D%20%EC%9D%B4%EC%83%81%20%EA%B0%90%EC%A7%80%20AI%20%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%20%EA%B0%9C%EB%B0%9C/code)

# Data 학습

1. MinMaxScaler 적용 [ Train, Test Data]
2. P에 대한 각 컬럼마다 모델을 적용시켜 이상치를 알아야 하기 때문에 총 8개의 다른 모델을 학습[P1 ~ P8]
3. TEST 데이터가 T시점까지 존재하기 때문에 T+1 인 시점 데이터를 생성[By. from statsmodels.tsa.holtwinters import ExponentialSmoothing]
4. 위 2번에서 학습한 모델을 갖고 각 컬럼에 맞게 예측한 뒤 submission.csv 파일로 저장하여 제출

## MinMaxScaler

```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(0, 1))

df_C.loc[:, x_c_col] = scaler.fit_transform(df_C.loc[:, x_c_col])

df_C.head()
```

## Model Fit

```python
from sklearn.ensemble import IsolationForest

# Isolation Forest 모델 학습
model_p1 = IsolationForest(contamination=0.05, random_state=42) # 이상치 비율 설정
model_p1.fit(x_train['P1'].values.reshape(-1,1))

model_p2 = IsolationForest(contamination=0.05, random_state=42)
model_p2.fit(x_train['P2'].values.reshape(-1,1))

model_p3 = IsolationForest(contamination=0.05, random_state=42)
model_p3.fit(x_train['P3'].values.reshape(-1,1))

model_p4 = IsolationForest(contamination=0.05, random_state=42)
model_p4.fit(x_train['P4'].values.reshape(-1,1))

model_p5 = IsolationForest(contamination=0.05, random_state=42)  
model_p5.fit(x_train['P5'].values.reshape(-1,1))

model_p6 = IsolationForest(contamination=0.05, random_state=42)  
model_p6.fit(x_train['P6'].values.reshape(-1,1))

model_p7 = IsolationForest(contamination=0.05, random_state=42)  
model_p7.fit(x_train['P7'].values.reshape(-1,1))

model_p8 = IsolationForest(contamination=0.05, random_state=42)
model_p8.fit(x_train['P8'].values.reshape(-1,1))
```

## Test data T+1 시점 생성

```python
test_C = pd.read_csv(f"../data/test/C/{i}.csv")
test_C = test_C[x_c_col]
test_C[:] = scaler.fit_transform(test_C[:])

predictions = {}
for j in x_c_col:
    model = ExponentialSmoothing(
        test_C[j],
        seasonal_periods=24,  # 24시간 주기
        trend=None,
        seasonal=None
    )

    fitted_model = model.fit()
    forecast = fitted_model.forecast(1).values  # 다음 1시점 예측
    predictions[j] = float(forecast)

predictions_df = pd.DataFrame([predictions])
result_df = pd.concat([test_C, predictions_df], ignore_index=True)
```

> 데이터 불러와서 MinMaxScaler 적용  
> 각 모델마다 다음 시점 예측해서 데이터 프레임의 마지막 행에 추가

## Predict

```python
result = []
p_predict = model_p1.predict(result_df['P1'].values.reshape(-1,1))[-1]
p_predict = (p_predict == -1).astype(int)
result.append(p_predict)

p_predict = model_p2.predict(result_df['P2'].values.reshape(-1,1))[-1]
p_predict = (p_predict == -1).astype(int)
result.append(p_predict)

***

sub_df.loc[count, 'flag_list'] = result # 제출 데이터에 저장
```

# 앞으로 추가해야 할 것
1. from sklearn.ensemble import IsolationForest 외에 다른 이상치 모델이 있는지 확인
> 그리고 매개변수에 대한 개념도 정리
2. T+1 시점 생성하는 ExponentialSmoothing 기법도 원리랑 개념 확인하기
3. 다른 변수들을 활용하는 방법 생각하기
